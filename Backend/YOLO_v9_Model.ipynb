{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Train YOLOv9 on a Custom Dataset\n",
        "---\n",
        "\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/WongKinYiu/yolov9)\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-2402.13616-b31b1b.svg)](https://arxiv.org/pdf/2402.13616.pdf)\n",
        "\n",
        "<br>\n",
        "\n",
        "![YOLOv9 Benchmark](https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/yolov9-benchmark.jpeg)"
      ],
      "metadata": {
        "id": "DQjdUKvQigN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ],
      "metadata": {
        "id": "m09A8n4djDwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5hX88yficL7",
        "outputId": "eb08ce36-4292-48c5-c814-7ca645e17bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 25 09:10:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ],
      "metadata": {
        "id": "UTprsNjHja4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowKDIT-jJ9k",
        "outputId": "5d5f8a9d-a4ee-4b17-8f33-90d7a42e51c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone and Install"
      ],
      "metadata": {
        "id": "qWRGGT7Zjjbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."
      ],
      "metadata": {
        "id": "9WyY-fboBLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pixgo4qnjdoU",
        "outputId": "18dc30f0-2f62-4877-9204-697b76008fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 325 (delta 134), reused 102 (delta 102), pack-reused 153\u001b[K\n",
            "Receiving objects: 100% (325/325), 2.26 MiB | 6.80 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n",
            "/content/yolov9\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Let's install additional packages that will be useful later on."
      ],
      "metadata": {
        "id": "bcx7KoNzqpgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPGqlohQqgAO",
        "outputId": "ff5dfea3-b05b-4e70-ad1b-5fcc1220ea41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "NgPBC3KWp74K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import roboflow\n",
        "\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "x0UqVaHLp9r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model weights"
      ],
      "metadata": {
        "id": "X8oLIkX2l2P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** In the YOLOv9 paper, versions yolov9-s and yolov9-m are also mentioned, but the weights for these models are not yet available in the YOLOv9 repository."
      ],
      "metadata": {
        "id": "0FieRuZnB4wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/weights"
      ],
      "metadata": {
        "id": "3r0CULdsmm7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"
      ],
      "metadata": {
        "id": "h7j3aUE7l1Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la {HOME}/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au6np1JS8eRB",
        "outputId": "fa4b6251-cf95-41db-ad74-084dc83fec9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 402440\n",
            "drwxr-xr-x 2 root root      4096 Mar  9 17:26 .\n",
            "drwxr-xr-x 1 root root      4096 Mar  9 17:26 ..\n",
            "-rw-r--r-- 1 root root  51508261 Feb 18 12:36 gelan-c.pt\n",
            "-rw-r--r-- 1 root root 117203713 Feb 18 12:36 gelan-e.pt\n",
            "-rw-r--r-- 1 root root 103153312 Feb 18 12:36 yolov9-c.pt\n",
            "-rw-r--r-- 1 root root 140217688 Feb 18 12:36 yolov9-e.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download example data"
      ],
      "metadata": {
        "id": "Dg29vEyLkTDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/data"
      ],
      "metadata": {
        "id": "YlrSXBxTwJCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_IMAGE_PATH = \"/content/India_002028.jpg\""
      ],
      "metadata": {
        "id": "hiqFDio2kX8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection with pre-trained COCO model"
      ],
      "metadata": {
        "id": "4dlfABN6m-LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gelan-c"
      ],
      "metadata": {
        "id": "6EPCiYcFComZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "16zSzeagejbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights {HOME}/weights/gelan-c.pt --conf 0.1 --source /content/yolov9/Screenshot_70.png --device 0"
      ],
      "metadata": {
        "id": "GzGyLetWoTWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63e1dac-9b77-4253-9804-644797975fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/weights/gelan-c.pt'], source=/content/yolov9/Screenshot_70.png, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 1e33dbb Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 467 layers, 25472640 parameters, 0 gradients, 102.8 GFLOPs\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/detect.py\", line 232, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/detect.py\", line 227, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov9/detect.py\", line 81, in run\n",
            "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
            "  File \"/content/yolov9/utils/dataloaders.py\", line 250, in __init__\n",
            "    raise FileNotFoundError(f'{p} does not exist')\n",
            "FileNotFoundError: /content/yolov9/Screenshot_70.png does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** By default, the results of each subsequent inference sessions are saved in `{HOME}/yolov9/runs/detect/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
      ],
      "metadata": {
        "id": "hflXfkBt3N0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=f\"{HOME}/yolov9/runs/detect/exp4/\", width=600)"
      ],
      "metadata": {
        "id": "sAE1P1BxpHYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yolov9-e"
      ],
      "metadata": {
        "id": "FCEIP-jFCsRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights {HOME}/weights/yolov9-e.pt --conf 0.1 --source /content/yolov9/Screenshot_70.png --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEQALIFaCuoX",
        "outputId": "28bcab72-5a00-4fa4-9053-3368bc1ba8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/weights/yolov9-e.pt'], source=/content/yolov9/Screenshot_70.png, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 1e33dbb Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 1119 layers, 69470144 parameters, 0 gradients, 244.0 GFLOPs\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/detect.py\", line 232, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/detect.py\", line 227, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov9/detect.py\", line 81, in run\n",
            "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
            "  File \"/content/yolov9/utils/dataloaders.py\", line 250, in __init__\n",
            "    raise FileNotFoundError(f'{p} does not exist')\n",
            "FileNotFoundError: /content/yolov9/Screenshot_70.png does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=f\"{HOME}/yolov9/runs/detect/exp2/dog.jpeg\", width=600)"
      ],
      "metadata": {
        "id": "llm4xIE_CyXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate and Download the Dataset"
      ],
      "metadata": {
        "id": "D7fZKrxsq_td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."
      ],
      "metadata": {
        "id": "eosmGt89vMO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4J3s_2_7p_gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovlfc6aoRonl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Custom Model"
      ],
      "metadata": {
        "id": "CTbGpF2IsZ24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the new content of the data.yaml file\n",
        "new_data_yaml_content = \"\"\"\n",
        "train: /Users/shrinivass/Downloads/Tri-NIT/India\n",
        "val: \"\"\n",
        "nc: 4\n",
        "names: ['Longitudinal Crack', 'Transverse Crack', 'Alligator Crack', 'Pothole']\n",
        "\"\"\"\n",
        "\n",
        "# Write the new content to the data.yaml file\n",
        "with open('/content/data.yaml', 'w') as f:\n",
        "    f.write(new_data_yaml_content)\n"
      ],
      "metadata": {
        "id": "tsyMKOGmRpOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the weights_path variable to an empty string to initialize the model with random weights\n",
        "weights_path = ''\n"
      ],
      "metadata": {
        "id": "3lzQhXb6SBHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "dataset_dir = \"/Users/shrinivass/Downloads/India/train\"\n",
        "\n",
        "# Set the paths for your data configuration file, weights, YOLO configuration file, and hyperparameter file\n",
        "data_yaml = \"/content/data.yaml\"\n",
        "weights_path = \"/content/weights/gelan-c.pt\"\n",
        "cfg_path = \"models/detect/gelan-c.yaml\"\n",
        "hyp_path = \"hyp.scratch-high.yaml\"\n",
        "\n",
        "# Change directory to YOLOv9 repository\n",
        "%cd {HOME}/yolov9\n",
        "\n",
        "# Command to train YOLO\n",
        "!python train.py \\\n",
        "--batch 8 --epochs 10 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {data_yaml} \\\n",
        "--weights {weights_path} \\\n",
        "--cfg {cfg_path} \\\n",
        "--hyp {hyp_path}\n"
      ],
      "metadata": {
        "id": "Rw12bSO_SHu8",
        "outputId": "456cc240-cb8e-45ea-f276-5e05ba350187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "2024-03-09 18:14:06.724474: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-09 18:14:06.724526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-09 18:14:06.726341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-09 18:14:07.796367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=/content/data.yaml, hyp=hyp.scratch-high.yaml, epochs=10, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLOv5 🚀 1e33dbb Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   5493724  models.yolo.DDetect                     [4, [256, 512, 512]]          \n",
            "gelan-c summary: 621 layers, 25440156 parameters, 25440140 gradients, 103.2 GFLOPs\n",
            "\n",
            "Transferred 931/937 items from /content/weights/gelan-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/utils/dataloaders.py\", line 474, in __init__\n",
            "    raise FileNotFoundError(f'{prefix}{p} does not exist')\n",
            "FileNotFoundError: \u001b[34m\u001b[1mtrain: \u001b[0m/Users/shrinivass/Downloads/Tri-NIT/India does not exist\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/train.py\", line 634, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/train.py\", line 528, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov9/train.py\", line 177, in train\n",
            "    train_loader, dataset = create_dataloader(train_path,\n",
            "  File \"/content/yolov9/utils/dataloaders.py\", line 120, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(\n",
            "  File \"/content/yolov9/utils/dataloaders.py\", line 479, in __init__\n",
            "    raise Exception(f'{prefix}Error loading data from {path}: {e}\\n{HELP_URL}') from e\n",
            "Exception: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /Users/shrinivass/Downloads/Tri-NIT/India: \u001b[34m\u001b[1mtrain: \u001b[0m/Users/shrinivass/Downloads/Tri-NIT/India does not exist\n",
            "See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python train.py \\\n",
        "--batch 8 --epochs 10 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/weights/gelan-c.pt \\\n",
        "--cfg models/detect/gelan-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "id": "N68Bdf4FsMYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78b222e-761d-4ed8-9983-f42fc135f073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "2024-03-09 17:28:26.085552: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-09 17:28:26.085608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-09 17:28:26.086969: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-09 17:28:27.103244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights={HOME}/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data={dataset.location}/data.yaml, hyp=hyp.scratch-high.yaml, epochs=10, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/train.py\", line 634, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/train.py\", line 503, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "  File \"/content/yolov9/utils/general.py\", line 478, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: {dataset.location}/data.yaml\n"
          ]
        }
      ]
    }
  ]
}